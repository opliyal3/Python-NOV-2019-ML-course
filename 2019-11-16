import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# pip install seaborn
from sklearn import datasets
import seaborn as sns
# load iris
iris = datasets.load_iris()
df1 = pd.DataFrame(iris.data, columns=iris.feature_names)
print(df1.shape)

df1['species'] = np.array([iris.target_names[i] for i in iris.target])
sns.pairplot(df1, hue='species')
plt.show()

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# pip install seaborn
from sklearn import datasets
import seaborn as sns
# load iris
iris = datasets.load_iris()
df1 = pd.DataFrame(iris.data, columns=iris.feature_names)
print(df1.shape)

df1['species'] = np.array([iris.target_names[i] for i in iris.target])
sns.pairplot(df1, hue='species')
plt.show()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df1[iris.feature_names], iris.target,
                                                    test_size=0.2, stratify=iris.target)
from sklearn.ensemble import RandomForestClassifier
rf1 = RandomForestClassifier(n_estimators=100, oob_score=True)
rf1.fit(X_train, y_train)

from sklearn.metrics import accuracy_score
predicted = rf1.predict(X_test)
accuracy = accuracy_score(y_test, predicted)
print(f'OOB estimator {rf1.oob_score_:.3}')
print(f'mean accuracy {accuracy:.3}')

from sklearn.metrics import confusion_matrix
cm = pd.DataFrame(confusion_matrix(y_test, predicted), columns=iris.target_names, index=iris.target_names)
sns.heatmap(cm, annot=True)
plt.show()

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn import datasets
from sklearn.decomposition import PCA

iris = datasets.load_iris()

X = iris.data
species = iris.target

fig = plt.figure(1, figsize=(8,8))
ax = Axes3D(fig, elev=-150, azim=110)
X_reduced = PCA(n_components=3).fit_transform(iris.data)
ax.scatter(X_reduced[:,0],X_reduced[:,1],X_reduced[:,2],c=species, cmap=plt.cm.Paired)

plt.show()

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn import datasets
from sklearn.decomposition import PCA

iris = datasets.load_iris()

X = iris.data
species = iris.target

fig = plt.figure(1, figsize=(8,8))
ax = Axes3D(fig, elev=-150, azim=110)
X_reduced = PCA(n_components=3).fit_transform(iris.data)
ax.scatter(X_reduced[:,0],X_reduced[:,1],X_reduced[:,2],c=species, cmap=plt.cm.Paired)

ax.set_title("3 CPA direction")
ax.set_xlabel("1st eigen value")
ax.set_ylabel("2nd eigne value")
ax.set_zlabel("3rd eigen value")
ax.w_xaxis.set_ticklabels([])
ax.w_yaxis.set_ticklabels([])
ax.w_zaxis.set_ticklabels([])
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn import datasets
from sklearn.decomposition import PCA

iris = datasets.load_iris()

X = iris.data
species = iris.target

fig = plt.figure(1, figsize=(8, 8))
ax = Axes3D(fig, elev=-150, azim=110)
print(plt.cm.get_cmap())
# print(d)

# magma, plasma, viridis
# https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html
X_reduced = PCA(n_components=3).fit_transform(iris.data)
ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=species, cmap=plt.get_cmap("viridis"))

ax.set_title("3 CPA direction")
ax.set_xlabel("1st eigen value")
ax.set_ylabel("2nd eigne value")
ax.set_zlabel("3rd eigen value")
ax.w_xaxis.set_ticklabels([])
ax.w_yaxis.set_ticklabels([])
ax.w_zaxis.set_ticklabels([])
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets
from sklearn import svm
from sklearn.decomposition import PCA

iris = datasets.load_iris()

pca = PCA(n_components=2)

data = pca.fit(iris.data).transform(iris.data)
print(pca.explained_variance_ratio_)
print(data.shape)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets
from sklearn import svm
from sklearn.decomposition import PCA

iris = datasets.load_iris()

pca = PCA(n_components=2)

data = pca.fit(iris.data).transform(iris.data)
print(pca.explained_variance_ratio_)
print(data.shape)

datamax = data.max(axis=0) + 1
datamin = data.min(axis=0) - 1
n = 4000
X, Y = np.meshgrid(np.linspace(datamin[0], datamax[0], n),
                   np.linspace(datamin[1], datamax[1], n))
svc = svm.SVC()
svc.fit(data, iris.target)
Z = svc.predict(np.c_[X.ravel(), Y.ravel()])
plt.contour(X, Y, Z.reshape(X.shape), levels=[-0.5, 0.5, 1.5, 2.5], colors=['c', 'm', 'y', 'k'])
for i, c in zip([0, 1, 2], ['r', 'g', 'b']):
    d = data[iris.target == i]
    plt.scatter(d[:, 0], d[:, 1], c=c)
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

from numpy import array
from sklearn.decomposition import PCA

A = array([[1, 2, 3], [3, 4, 5], [5, 6, 7], [7, 8, 9]])
print(A)

pca = PCA(2)
pca.fit(A)
print("components", pca.components_)
print("variance", pca.explained_variance_)
B = pca.transform(A)
print(B)

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

from numpy import array
from numpy import cov
from numpy import mean
from numpy.linalg import eig

A = array([[1, 2, 3], [3, 4, 5], [5, 6, 7], [7, 8, 9]])
print(A)
M = mean(A.T, axis=1)
print(M)
M2 = mean(A.T)
print(M2)
M3 = mean(A, axis=1)
print(M3)
C = A-M
print(C)
V = cov(C.T)
print(V)
values, vectors = eig(V)
print("vectors,",vectors)
print("values", values)
P = vectors.T.dot(C.T)
print("project", P.T)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


pip install tensorflow


import tensorflow as tf

hello1 = tf.constant('hello tensorflow from python3.7')
print(tf.__version__)
print(hello1)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


conda create -n tf2py37 python=3.7
conda activate tf2py37
conda deactivate

conda install tensorflow-gpu

conda create -n tf2py37intel python=3.7
conda activate tf2py37intel
conda install tensorflow
conda deactivate

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

NVidiaLab


conda info --envs

C:\Users\Admin\.conda\envs\tf2py37\python.exe

import tensorflow as tf

hello1 = tf.constant('hello tensorflow from Nvidia CUDA/CUDNN')
print(tf.__version__)
print(hello1)


IntelCondaLab
C:\Users\Admin\.conda\envs\tf2py37intel\python.exe
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf

tf.compat.v1.disable_eager_execution()
hello1 = tf.constant('hello tensorflow from python3.7')
print(tf.__version__)
with tf.compat.v1.Session() as session:
    print(session.run(hello1))
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import numpy as np

print(tf.__version__)

a = np.array([5, 3, 8])
b = np.array([3, -1, 8])
c = np.add(a, b)
print(c)

a2 = tf.constant([5,3,8])
b2 = tf.constant([3,-1,2])
c2 = tf.add(a,b)
print(c2)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import numpy as np

tf.compat.v1.disable_eager_execution()
print(tf.__version__)

a = np.array([5, 3, 8])
b = np.array([3, -1, 8])
c = np.add(a, b)
print(c)

a2 = tf.constant([5, 3, 8])
b2 = tf.constant([3, -1, 2])
c2 = tf.add(a, b)
print(c2)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import numpy as np

print(tf.__version__)

a = np.array([5, 3, 8])
b = np.array([3, -1, 8])
c = np.add(a, b)
print(c)

a2 = tf.constant([5.0, 3.4, 8.5])
b2 = tf.constant([3, -1.0, 2.9])
c2 = tf.add(a2, b2)
print(c2)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import numpy as np

tf.compat.v1.disable_eager_execution()
print(tf.__version__)

a = np.array([5, 3, 8])
b = np.array([3, -1, 8])
c = np.add(a, b)
print(c)

a2 = tf.constant([5.0, 3, 8])
b2 = tf.constant([3, -1, 2])
c2 = tf.add(a2, b2)
print(c2)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf

@tf.function
def add(p, q):
    return tf.math.add(p, q) * 2


print(add([1, 2, 3], [4, 5, 6]))

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf

tf.compat.v1.disable_eager_execution()

a = tf.compat.v1.placeholder(dtype=tf.int32, shape=(None,))
b = tf.compat.v1.placeholder(dtype=tf.int32, shape=(None,))
c = tf.compat.v1.add(a, b)

with tf.compat.v1.Session() as session:
    result = session.run(c, feed_dict={a: [1, 3, 5], b: [2, 4, 6]})
    print(result)




conda deactivate

conda activate

conda info --envs

conda activate tf2py37intel

conda install numpy scipy mlk-service libpython m2w64-toolchain nose sphinx git

conda install numpy scipy mkl-service libpython m2w64-toolchain nose sphinx git


pip install theano msgpack parameterized



theano_lab

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import theano
from theano import tensor

a = tensor.dscalar()
b = tensor.dscalar()
c = 4 * a ** 2 + 6 * b ** 2
f = theano.function([a, b], c)
result = f(1.5, 2.5)
print(result)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
pip install keras cython
conda deactivate
conda activate tf2py37


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
1/(1+exp(-x))
Max(0,x)
tanh(x)

https://www.sympygamma.com/input/?i=tanh%28x%29


import tensorflow as tf

vector = [3.0, -1.0, 2.4, 5.9, 0.001, 8.5, -0.0000000001]
result1 = tf.nn.relu(vector)
result2 = tf.nn.sigmoid(vector)
print(result1)
print(result2)

https://www.kaggle.com/uciml/pima-indians-diabetes-database/data#



data\diabetes.csv

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import numpy
from keras.layers import Dense
from keras.models import Sequential
import os

print(os.getcwd())

dataset1 = numpy.loadtxt('data\\diabetes.csv', delimiter=',', skiprows=1)
print(type(dataset1), dataset1.shape)

inputList = dataset1[:, 0:8]
resultList = dataset1[:, 8]
print(inputList[:5])
print(numpy.unique(resultList))
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import numpy
from keras.layers import Dense
from keras.models import Sequential
import os

print(os.getcwd())

dataset1 = numpy.loadtxt('data\\diabetes.csv', delimiter=',', skiprows=1)
print(type(dataset1), dataset1.shape)

inputList = dataset1[:, 0:8]
resultList = dataset1[:, 8]
print(inputList[:5])
print(numpy.unique(resultList))

model = Sequential()
model.add(Dense(14, input_dim=8, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import numpy
from keras.layers import Dense
from keras.models import Sequential
import os

print(os.getcwd())

dataset1 = numpy.loadtxt('data\\diabetes.csv', delimiter=',', skiprows=1)
print(type(dataset1), dataset1.shape)

inputList = dataset1[:, 0:8]
resultList = dataset1[:, 8]
print(inputList[:5])
print(numpy.unique(resultList))

model = Sequential()
model.add(Dense(14, input_dim=8, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())

result_history = model.fit(inputList, resultList, epochs=200, batch_size=20)

score = model.evaluate(inputList, resultList)

print(type(model.metrics_names))


cmd
cd c:\USers\Admin\notebook
jupyter-notebook


import numpy
from keras.layers import Dense
from keras.models import Sequential
import os

print(os.getcwd())

dataset1 = numpy.loadtxt('data\\diabetes.csv', delimiter=',', skiprows=1)
print(type(dataset1), dataset1.shape)

inputList = dataset1[:, 0:8]
resultList = dataset1[:, 8]
print(inputList[:5])
print(numpy.unique(resultList))

model = Sequential()
model.add(Dense(14, input_dim=8, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())

result_history = model.fit(inputList, resultList, epochs=200, batch_size=20)



score = model.evaluate(inputList, resultList)
print(type(model.metrics_names))




for element in model.metrics_names:
    print(element)
for key in range(2):
    print(f"{model.metrics_names[key]} value:{score[key]}")


demo40
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import numpy
from keras.layers import Dense
from keras.models import Sequential
import os

print(os.getcwd())

dataset1 = numpy.loadtxt('data\\diabetes.csv', delimiter=',', skiprows=1)
print(type(dataset1), dataset1.shape)

inputList = dataset1[:, 0:8]
resultList = dataset1[:, 8]
print(inputList[:5])
print(numpy.unique(resultList))

model = Sequential()
model.add(Dense(14, input_dim=8, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())

result_history = model.fit(inputList, resultList, validation_split=0.1, epochs=200, batch_size=20)

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
scores = model.evaluate(inputList, resultList)
print(f"{model.metrics_names[0]}:{scores[0]}")
print(f"{model.metrics_names[1]}:{scores[1]}")
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import matplotlib.pyplot as plt
plt.plot(result_history.history['accuracy'])
plt.plot(result_history.history['loss'])
plt.legend(['acc','loss'], loc='upper right')

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
plt.plot(result_history.history['val_accuracy'])
plt.plot(result_history.history['val_loss'])
plt.legend(['acc','loss'], loc='upper right')
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
plt.plot(result_history.history['accuracy'])
plt.plot(result_history.history['val_accuracy'])
plt.legend(['acc','val_acc'], loc='upper right')

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
plt.plot(result_history.history['loss'])
plt.plot(result_history.history['val_loss'])
plt.legend(['loss', 'val_loss'], loc='upper right')

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import numpy
from keras.layers import Dense
from keras.models import Sequential
import os
from sklearn.model_selection import train_test_split

print(os.getcwd())

dataset1 = numpy.loadtxt('data\\diabetes.csv', delimiter=',', skiprows=1)
print(type(dataset1), dataset1.shape)

inputList = dataset1[:, 0:8]
resultList = dataset1[:, 8]

feature_train, feature_test, label_train, label_test = train_test_split(inputList, resultList, test_size=0.3)





print(inputList[:5])
print(numpy.unique(resultList))

model = Sequential()
model.add(Dense(14, input_dim=8, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())

result_history = model.fit(feature_train, label_train, epochs=200, batch_size=20,
                           validation_data=(feature_test, label_test))

score = model.evaluate(inputList, resultList)

print(type(model.metrics_names))

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import numpy
from keras.layers import Dense
from keras.models import Sequential
import os
from sklearn.model_selection import StratifiedKFold

print(os.getcwd())

dataset1 = numpy.loadtxt('data\\diabetes.csv', delimiter=',', skiprows=1)
print(type(dataset1), dataset1.shape)

inputList = dataset1[:, 0:8]
resultList = dataset1[:, 8]
print(inputList[:5])
print(numpy.unique(resultList))

fiveFold = StratifiedKFold(n_splits=5, shuffle=True)
totalScores = []

model = Sequential()
model.add(Dense(14, input_dim=8, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())

for train, test in fiveFold.split(inputList, resultList):
    result_history = model.fit(inputList[train], resultList[train], epochs=200, batch_size=20, verbose=0)

    score = model.evaluate(inputList[test], resultList[test])

    totalScores.append(score[1] * 100)

    print(type(model.metrics_names))
    print(f"got a result with loss:{score[0]}, accuracy:{score[1]}")
print(f"total 5 result:{numpy.mean(totalScores)}, std:{numpy.std(totalScores)}")
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import numpy
from keras.layers import Dense
from keras.models import Sequential
import os
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import StratifiedKFold, cross_val_score

print(os.getcwd())

dataset1 = numpy.loadtxt('data\\diabetes.csv', delimiter=',', skiprows=1)
print(type(dataset1), dataset1.shape)

inputList = dataset1[:, 0:8]
resultList = dataset1[:, 8]
print(inputList[:5])
print(numpy.unique(resultList))


def create_default_model():
    model = Sequential()
    model.add(Dense(14, input_dim=8, activation='relu'))
    model.add(Dense(12, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    print(model.summary())
    return model


model = KerasClassifier(build_fn=create_default_model, epochs=200, batch_size=20, verbose=0)
fiveFold = StratifiedKFold(n_splits=5, shuffle=True)

result = cross_val_score(model, inputList, resultList, cv=fiveFold)
print(f"result mean={result.mean()}, result std={result.std()}")
